{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T19:31:36.196144700Z",
     "start_time": "2023-12-20T19:31:33.912361800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# reversed indicators\n",
    "reversed = ['Unemployment, total (% of total labor force) (modeled ILO estimate)',\n",
    "            'Mortality rate, under-5 (per 1,000 live births)',\n",
    "            'CO2 emissions (metric tons per capita)']\n",
    "# sub indexes\n",
    "education = [ 'Unemployment, total (% of total labor force) (modeled ILO estimate)',\n",
    "              'School enrollment, secondary (% net)',\n",
    "              'School enrollment, primary (% net)',\n",
    "              'School enrollment, tertiary (% gross)']\n",
    "economic = ['World Development Indicators',\n",
    "            'Access to electricity (% of population)',\n",
    "            'GDP per capita (current US$)']\n",
    "health = ['Mortality rate, under-5 (per 1,000 live births)',\n",
    "          'Life expectancy at birth, total(years)']\n",
    "environment = ['CO2 emissions (metric tons per capita)']\n",
    "security = ['Democracy index',\n",
    "            'Control of Corruption: Estimate',\n",
    "            'Government Effectiveness: Estimate',\n",
    "            'Political Stability and Absence of Violence/Terrorism: Estimate',\n",
    "            'Regulatory Quality: Estimate',\n",
    "            'Rule of Law: Estimate',\n",
    "            'Voice and Accountability: Estimate']\n",
    "list_of_sub_indexes = [education, economic, environment, health, security]\n",
    "sub_indexes = ['Education', 'Economic', 'Health', 'Environment', 'Safety']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T19:31:36.218307100Z",
     "start_time": "2023-12-20T19:31:36.202002400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "list_of_dfs = []\n",
    "def convert_separate(year):\n",
    "    data = pd.read_csv(f'DS_Index - {year}.csv')\n",
    "    # safety index cleaning\n",
    "    safety = pd.read_excel(\"Safety.xlsx\")\n",
    "    names = ['Control of Corruption: Estimate', 'Government Effectiveness: Estimate', 'Political Stability and Absence of Violence/Terrorism: Estimate', 'Regulatory Quality: Estimate', 'Rule of Law: Estimate', 'Voice and Accountability: Estimate']\n",
    "    safety = safety[safety['Series Name'].isin(names)]\n",
    "    # merging data\n",
    "    for i in range(len(names)):\n",
    "        s = safety[safety['Series Name'] == names[i]][['Country Code', f'{year} [YR{year}]']]\n",
    "        col = s.columns.tolist()\n",
    "        col[-1] = names[i]\n",
    "        s.columns = col\n",
    "        data = data.merge(s, on=['Country Code'])\n",
    "\n",
    "    # deleting unnecessary information\n",
    "    to_delete = ['Rail lines (total route-km)', 'Net migration', 'Annual freshwater withdrawals, total (% of internal resources)']\n",
    "    data.drop(labels=to_delete, inplace=True, axis=1)\n",
    "\n",
    "    # converting to float\n",
    "    data.replace('..', np.nan, inplace=True)\n",
    "    cols = data.columns\n",
    "    cols = cols[2:]\n",
    "    data[cols] = data[cols].astype(str)\n",
    "    data = data.apply(lambda x: x.str.replace(',','.'))\n",
    "    data[cols] = data[cols].astype(float)\n",
    "\n",
    "    #remove rows with more than 3 NaN\n",
    "    data = data[data.isnull().sum(axis=1) < 3]\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "    # filling missing values with KNN, k = 5\n",
    "    data[cols] = pd.DataFrame(imputer.fit_transform(data[cols]),columns = cols)\n",
    "\n",
    "    # normalizing data\n",
    "    data[cols]=(data[cols]-data[cols].min())/(data[cols].max()-data[cols].min())\n",
    "    for i in reversed:\n",
    "        data[i] = 1 - data[i]\n",
    "\n",
    "    # factorizing security\n",
    "    fa_s = FactorAnalyzer(rotation='varimax')\n",
    "    fa_s.fit(data[security])\n",
    "    # processing loadings\n",
    "    loadings = pd.DataFrame(fa_s.loadings_)\n",
    "    loadings = loadings.apply(lambda x: x*x)\n",
    "    loadings = loadings.apply(lambda column: column/column.sum(), axis=0)\n",
    "    # creating temporary intermediate indicators\n",
    "    for i in loadings.columns:\n",
    "        data[str(i)] = 0\n",
    "        index = 0\n",
    "        for weight in loadings[i]:\n",
    "            if weight > 0.1:\n",
    "                data[str(i)] += weight*data[security[index]]\n",
    "            index += 1\n",
    "    expl_var = fa_s.get_factor_variance()[0]\n",
    "\n",
    "    # computing sub indexes and index\n",
    "    data['Economic'] = data[economic].mean(axis=1)\n",
    "    data['Environment'] = data[environment].mean(axis=1)\n",
    "    data['Education'] = (data[education[0]]*0.5 + (data[education[1]]*0.5/3 + data[education[2]]*0.5/3 + data[education[3]]*0.5/3))\n",
    "    data['Health'] = (data[health[0]]*0.3 + data[health[1]]*0.7)\n",
    "    data['Safety'] = 0\n",
    "    for i in loadings.columns:\n",
    "        coef = expl_var[i]/ expl_var.sum()\n",
    "        data['Safety'] += data[str(i)] * coef\n",
    "\n",
    "    # drop temporary indicators\n",
    "    data.drop(labels = [str(i) for i in loadings.columns], axis=1, inplace=True)\n",
    "\n",
    "    coef_for_environment = 0.1\n",
    "    coef_for_others = (1 - coef_for_environment)/(len(list_of_sub_indexes)-1)\n",
    "\n",
    "    data['Prosperity index'] = data['Environment'] * coef_for_environment + coef_for_others * (data['Economic'] + data['Education'] + data['Health'] + data['Safety'])\n",
    "\n",
    "    #loading to excel normalized version with indexes\n",
    "    data.to_excel(f\"{year}.xlsx\")\n",
    "\n",
    "    data.sort_values('Prosperity index', inplace=True, ascending=False)\n",
    "\n",
    "    #loading result to excel\n",
    "    res = data[['Country Name', 'Country Code'] + sub_indexes + ['Prosperity index']].reset_index(drop=True)\n",
    "    res.index += 1\n",
    "    res.reset_index(names=\"Rank\", inplace = True)\n",
    "    res.index += 1\n",
    "    res.to_excel(f\"{year}result.xlsx\")\n",
    "\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data.index += 1\n",
    "    data.reset_index(inplace=True, names='Rank')\n",
    "    data.index += 1\n",
    "    data = pd.concat([data], keys=[f'{year}'], names=['Year'])\n",
    "    list_of_dfs.append(data)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T19:31:36.228802Z",
     "start_time": "2023-12-20T19:31:36.218307100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "years = [x for x in range(2015, 2021)]\n",
    "for i in years:\n",
    "    convert_separate(i)\n",
    "\n",
    "result = pd.concat(list_of_dfs)\n",
    "result.to_excel('result.xlsx')\n",
    "result[['Country Name', 'Country Code'] + sub_indexes + ['Prosperity index']].to_excel(\"result_indexes.xlsx\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T19:31:43.423615500Z",
     "start_time": "2023-12-20T19:31:36.227655200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing for 2015"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 217, in _count_physical_cores\n",
      "    raise ValueError(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "Index(['Australia', 'Austria', 'Belgium', 'Bahamas. The', 'Barbados', 'Canada',\n",
      "       'Switzerland', 'Chile', 'Costa Rica', 'Cyprus', 'Czechia', 'Germany',\n",
      "       'Denmark', 'Spain', 'Estonia', 'Finland', 'France', 'United Kingdom',\n",
      "       'Hong Kong SAR. China', 'Ireland', 'Iceland', 'Israel', 'Italy',\n",
      "       'Japan', 'Korea. Rep.', 'Lithuania', 'Luxembourg', 'Latvia', 'Malta',\n",
      "       'Mauritius', 'Netherlands', 'Norway', 'New Zealand', 'Poland',\n",
      "       'Puerto Rico', 'Portugal', 'Slovenia', 'Sweden', 'Uruguay',\n",
      "       'United States'],\n",
      "      dtype='object', name='Country Name')\n",
      "Cluster 1:\n",
      "Index(['Albania', 'United Arab Emirates', 'Argentina', 'Armenia', 'Azerbaijan',\n",
      "       'Bulgaria', 'Bahrain', 'Bosnia and Herzegovina', 'Belarus', 'Belize',\n",
      "       'Bolivia', 'Brazil', 'Brunei Darussalam', 'Bhutan', 'Botswana', 'China',\n",
      "       'Colombia', 'Cabo Verde', 'Cuba', 'Dominican Republic', 'Algeria',\n",
      "       'Ecuador', 'Egypt. Arab Rep.', 'Fiji', 'Georgia', 'Ghana', 'Greece',\n",
      "       'Croatia', 'Hungary', 'Indonesia', 'India', 'Iran. Islamic Rep.',\n",
      "       'Jamaica', 'Jordan', 'Kazakhstan', 'Kyrgyz Republic', 'Kuwait',\n",
      "       'St. Lucia', 'Sri Lanka', 'Morocco', 'Moldova', 'Mexico',\n",
      "       'North Macedonia', 'Montenegro', 'Mongolia', 'Malaysia', 'Namibia',\n",
      "       'Oman', 'Panama', 'Peru', 'Philippines', 'West Bank and Gaza', 'Qatar',\n",
      "       'Romania', 'Russian Federation', 'Saudi Arabia', 'El Salvador',\n",
      "       'Serbia', 'Sao Tome and Principe', 'Suriname', 'Slovak Republic',\n",
      "       'Seychelles', 'Thailand', 'Tonga', 'Tunisia', 'Turkiye', 'Ukraine',\n",
      "       'St. Vincent and the Grenadines', 'Viet Nam', 'Samoa', 'South Africa'],\n",
      "      dtype='object', name='Country Name')\n",
      "Cluster 2:\n",
      "Index(['Afghanistan', 'Burundi', 'Benin', 'Burkina Faso', 'Bangladesh',\n",
      "       'Cote d'Ivoire', 'Cameroon', 'Congo. Rep.', 'Djibouti', 'Ethiopia',\n",
      "       'Guinea', 'Equatorial Guinea', 'Guatemala', 'Honduras', 'Kenya',\n",
      "       'Cambodia', 'Lao PDR', 'Liberia', 'Lesotho', 'Madagascar', 'Mali',\n",
      "       'Mozambique', 'Mauritania', 'Malawi', 'Niger', 'Nicaragua', 'Nepal',\n",
      "       'Pakistan', 'Rwanda', 'Sudan', 'Senegal', 'Sierra Leone', 'South Sudan',\n",
      "       'Eswatini', 'Syrian Arab Republic', 'Chad', 'Togo', 'Tajikistan',\n",
      "       'Timor-Leste', 'Tanzania', 'Uganda', 'Vanuatu', 'Zimbabwe'],\n",
      "      dtype='object', name='Country Name')\n"
     ]
    }
   ],
   "source": [
    "year = 2015\n",
    "data = pd.read_csv(f'DS_Index - {year}.csv')\n",
    "# safety index cleaning\n",
    "safety = pd.read_excel(\"Safety.xlsx\")\n",
    "names = ['Control of Corruption: Estimate', 'Government Effectiveness: Estimate', 'Political Stability and Absence of Violence/Terrorism: Estimate', 'Regulatory Quality: Estimate', 'Rule of Law: Estimate', 'Voice and Accountability: Estimate']\n",
    "safety = safety[safety['Series Name'].isin(names)]\n",
    "# merging data\n",
    "for i in range(len(names)):\n",
    "    s = safety[safety['Series Name'] == names[i]][['Country Code', f'{year} [YR{year}]']]\n",
    "    col = s.columns.tolist()\n",
    "    col[-1] = names[i]\n",
    "    s.columns = col\n",
    "    data = data.merge(s, on=['Country Code'])\n",
    "\n",
    "# deleting unnecessary information\n",
    "to_delete = ['Rail lines (total route-km)', 'Net migration', 'Annual freshwater withdrawals, total (% of internal resources)']\n",
    "data.drop(labels=to_delete, inplace=True, axis=1)\n",
    "\n",
    "# converting to float\n",
    "data.replace('..', np.nan, inplace=True)\n",
    "cols = data.columns\n",
    "cols = cols[2:]\n",
    "data[cols] = data[cols].astype(str)\n",
    "data = data.apply(lambda x: x.str.replace(',','.'))\n",
    "data[cols] = data[cols].astype(float)\n",
    "\n",
    "#remove rows with more than 3 NaN\n",
    "data = data[data.isnull().sum(axis=1) < 3]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# filling missing values with KNN, k = 5\n",
    "data[cols] = pd.DataFrame(imputer.fit_transform(data[cols]),columns = cols)\n",
    "\n",
    "# normalizing data\n",
    "data[cols]=(data[cols]-data[cols].min())/(data[cols].max()-data[cols].min())\n",
    "for i in reversed:\n",
    "    data[i] = 1 - data[i]\n",
    "\n",
    "# cluster analysis\n",
    "clusters_data = data.drop(labels=['Country Name', 'Country Code'], axis=1)\n",
    "\n",
    "#determining number of clusters\n",
    "numClusters = [i for i in range(1, 11)]\n",
    "SSE = []\n",
    "for k in numClusters:\n",
    "    k_means = KMeans(init='random', n_clusters=k, max_iter=50, random_state=1, n_init=10)\n",
    "    k_means.fit(clusters_data)\n",
    "    SSE.append(k_means.inertia_)\n",
    "\n",
    "kl = KneeLocator(range(1, 11), SSE, curve=\"convex\", direction=\"decreasing\")\n",
    "number_of_clusters = kl.elbow\n",
    "k_means = KMeans(init='random', n_clusters=number_of_clusters, max_iter=50, random_state=1, n_init=10)\n",
    "k_means.fit(clusters_data)\n",
    "labels = k_means.labels_\n",
    "clusters = pd.DataFrame(labels, index=data['Country Name'], columns=['Cluster ID'])\n",
    "#print countries in clusters\n",
    "for i in range(number_of_clusters):\n",
    "    print(f\"Cluster {i}:\")\n",
    "    print(clusters[clusters['Cluster ID'] == i].index)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(numClusters, SSE)\n",
    "# plt.xlabel('Number of Clusters')\n",
    "# plt.ylabel('SSE')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T19:31:49.952745100Z",
     "start_time": "2023-12-20T19:31:43.433873Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8527595986108871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\factor_analyzer\\utils.py:244: UserWarning: The inverse of the variance-covariance matrix was calculated using the Moore-Penrose generalized matrix inversion, due to its determinant being at or very close to zero.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[['Democracy index',\n  'Control of Corruption: Estimate',\n  'Government Effectiveness: Estimate',\n  'Political Stability and Absence of Violence/Terrorism: Estimate',\n  'Regulatory Quality: Estimate',\n  'Rule of Law: Estimate',\n  'Voice and Accountability: Estimate']]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = []\n",
    "# finding \"factorizable\" sub_indexes\n",
    "for i in list_of_sub_indexes:\n",
    "    if len(i) > 1:\n",
    "        kmo_all,kmo_model=calculate_kmo(data[i])\n",
    "        if kmo_model > 0.7:\n",
    "            print(kmo_model)\n",
    "            l.append(i)\n",
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T19:31:50.013737400Z",
     "start_time": "2023-12-20T19:31:49.955747800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# factorizing security\n",
    "fa_s = FactorAnalyzer(rotation='varimax')\n",
    "fa_s.fit(data[security])\n",
    "# processing loadings\n",
    "loadings = pd.DataFrame(fa_s.loadings_)\n",
    "loadings = loadings.apply(lambda x: x*x)\n",
    "loadings = loadings.apply(lambda column: column/column.sum(), axis=0)\n",
    "# creating temporary intermediate indicators\n",
    "for i in loadings.columns:\n",
    "    data[str(i)] = 0\n",
    "    index = 0\n",
    "    for weight in loadings[i]:\n",
    "        if weight > 0.1:\n",
    "            data[str(i)] += weight*data[security[index]]\n",
    "        index += 1\n",
    "expl_var = fa_s.get_factor_variance()[0]\n",
    "\n",
    "# computing sub indexes and index\n",
    "data['Economic'] = data[economic].mean(axis=1)\n",
    "data['Environment'] = data[environment].mean(axis=1)\n",
    "data['Education'] = (data[education[0]]*0.5 + (data[education[1]]*0.5/3 + data[education[2]]*0.5/3 + data[education[3]]*0.5/3))\n",
    "data['Health'] = (data[health[0]]*0.3 + data[health[1]]*0.7)\n",
    "data['Safety'] = 0\n",
    "for i in loadings.columns:\n",
    "    coef = expl_var[i]/ expl_var.sum()\n",
    "    data['Safety'] += data[str(i)] * coef\n",
    "\n",
    "# drop temporary indicators\n",
    "data.drop(labels = [str(i) for i in loadings.columns], axis=1, inplace=True)\n",
    "\n",
    "coef_for_environment = 0.1\n",
    "coef_for_others = (1 - coef_for_environment)/(len(list_of_sub_indexes)-1)\n",
    "\n",
    "data['Prosperity index'] = data['Environment'] * coef_for_environment + coef_for_others * (data['Economic'] + data['Education'] + data['Health'] + data['Safety'])\n",
    "\n",
    "#loading to excel normalized version with indexes\n",
    "data.to_excel(f\"test{year}.xlsx\")\n",
    "\n",
    "data.sort_values('Prosperity index', inplace=True, ascending=False)\n",
    "\n",
    "#loading result to excel\n",
    "res = data[['Country Name', 'Country Code'] + sub_indexes + ['Prosperity index']].reset_index(drop=True)\n",
    "res.index += 1\n",
    "res.reset_index(names=\"Rank\", inplace = True)\n",
    "res.index += 1\n",
    "res.to_excel(f\"test{year}result.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T19:31:50.337866900Z",
     "start_time": "2023-12-20T19:31:50.018740500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "     Rank          Country Name Country Code  Education  Economic    Health  \\\n1       1               Iceland          ISL   0.847960  0.685461  0.888550   \n2       2  Hong Kong SAR. China          HKG   0.839115  0.636897  0.967071   \n3       3           New Zealand          NZL   0.838726  0.634869  0.792880   \n4       4                Sweden          SWE   0.791985  0.681395  0.795996   \n5       5             Australia          AUS   0.874232  0.680399  0.742482   \n..    ...                   ...          ...        ...       ...       ...   \n150   150                 Sudan          SDN   0.342927  0.323884  0.877536   \n151   151              Djibouti          DJI   0.173905  0.405123  0.691086   \n152   152                 Nepal          NPL   0.533644  0.454028  0.176413   \n153   153           Congo. Rep.          COG   0.323841  0.270804  0.243658   \n154   154           South Sudan          SSD   0.302758  0.074536  0.348914   \n\n     Environment    Safety  Prosperity index  \n1       0.879652  0.688766          0.787881  \n2       0.843174  0.652936          0.780922  \n3       0.975392  0.746198          0.775391  \n4       0.833961  0.734274          0.759217  \n5       0.841534  0.698900          0.758256  \n..           ...       ...               ...  \n150     0.559629  0.079087          0.421235  \n151     0.936669  0.184889          0.421043  \n152     0.995981  0.246601          0.417002  \n153     0.999804  0.157382          0.324010  \n154     0.976946  0.069966          0.276834  \n\n[154 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Country Name</th>\n      <th>Country Code</th>\n      <th>Education</th>\n      <th>Economic</th>\n      <th>Health</th>\n      <th>Environment</th>\n      <th>Safety</th>\n      <th>Prosperity index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Iceland</td>\n      <td>ISL</td>\n      <td>0.847960</td>\n      <td>0.685461</td>\n      <td>0.888550</td>\n      <td>0.879652</td>\n      <td>0.688766</td>\n      <td>0.787881</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Hong Kong SAR. China</td>\n      <td>HKG</td>\n      <td>0.839115</td>\n      <td>0.636897</td>\n      <td>0.967071</td>\n      <td>0.843174</td>\n      <td>0.652936</td>\n      <td>0.780922</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>New Zealand</td>\n      <td>NZL</td>\n      <td>0.838726</td>\n      <td>0.634869</td>\n      <td>0.792880</td>\n      <td>0.975392</td>\n      <td>0.746198</td>\n      <td>0.775391</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Sweden</td>\n      <td>SWE</td>\n      <td>0.791985</td>\n      <td>0.681395</td>\n      <td>0.795996</td>\n      <td>0.833961</td>\n      <td>0.734274</td>\n      <td>0.759217</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Australia</td>\n      <td>AUS</td>\n      <td>0.874232</td>\n      <td>0.680399</td>\n      <td>0.742482</td>\n      <td>0.841534</td>\n      <td>0.698900</td>\n      <td>0.758256</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>150</td>\n      <td>Sudan</td>\n      <td>SDN</td>\n      <td>0.342927</td>\n      <td>0.323884</td>\n      <td>0.877536</td>\n      <td>0.559629</td>\n      <td>0.079087</td>\n      <td>0.421235</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>151</td>\n      <td>Djibouti</td>\n      <td>DJI</td>\n      <td>0.173905</td>\n      <td>0.405123</td>\n      <td>0.691086</td>\n      <td>0.936669</td>\n      <td>0.184889</td>\n      <td>0.421043</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>152</td>\n      <td>Nepal</td>\n      <td>NPL</td>\n      <td>0.533644</td>\n      <td>0.454028</td>\n      <td>0.176413</td>\n      <td>0.995981</td>\n      <td>0.246601</td>\n      <td>0.417002</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>153</td>\n      <td>Congo. Rep.</td>\n      <td>COG</td>\n      <td>0.323841</td>\n      <td>0.270804</td>\n      <td>0.243658</td>\n      <td>0.999804</td>\n      <td>0.157382</td>\n      <td>0.324010</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>154</td>\n      <td>South Sudan</td>\n      <td>SSD</td>\n      <td>0.302758</td>\n      <td>0.074536</td>\n      <td>0.348914</td>\n      <td>0.976946</td>\n      <td>0.069966</td>\n      <td>0.276834</td>\n    </tr>\n  </tbody>\n</table>\n<p>154 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T19:31:50.363474500Z",
     "start_time": "2023-12-20T19:31:50.343104100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
